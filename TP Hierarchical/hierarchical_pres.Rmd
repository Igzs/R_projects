---
title: "Week 8"
subtitle: "Hierarchical Clustering"
author: Igor FIDALGO
date: "`r format(Sys.time())`"
output: 
  html_document:
    toc: true
    toc_depth: 2
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercice 1
Download the iris dataset and import it into R.

```{r cars}
summary(cars)
```

## Exercice 2
Choose randomly 40 observations of the iris dataset and store the sample dataset into sampleiris.

```{r}
```
## Exercice 3
Calculate the euclidean distances between the flowers. Store the results in a matrix called D. (Remark: the last column of the dataset is the class labels of the flowers)

```{r}
```
## Exercice 4
Calculate the euclidean distances between the flowers. Store the results in a matrix called D. (Remark: the last column of the dataset is the class labels of the flowers)

```{r }
 
```
## Exercice 5
Plot the dendrogram.

```{r  }
 
```
## Exercice 6
Calculate the euclidean distances between the flowers. Store the results in a matrix called D. (Remark: the last column of the dataset is the class labels of the flowers)

```{r  }
 
```
## Exercice 7
To cut the dendrogram and obtain a clustering use the cutree. You can choose the number of clusters you wish to obtain, or you can cut by choosing the height from the dendrogram figure. Cut the dendrogram in order to obtain 3 clusters. Store the results into vector groups.avg.

```{r  }
 
```
## Exercice 8
Visualize the cut tree using the function rect.hclust(). You can choose the colors of the rectangles too!

```{r  }
 
```
## Exercice 9
Compare the obtained results obtained with Hierarchical clustering and the real class labels of the flowers (function table()). Interpret the results.

```{r  }
 
```
## Exercice 10
Now apply the Hierarchical clustering on the iris dataset (the 150 observations). Choose 3 clusters and compare the results with the real class labels. Compare different methods of Hierarchical clustering (average, complete and single linkages).

```{r  }
 
```